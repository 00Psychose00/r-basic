---
title: "Tema 11 - Introducción a distribuciones de probabilidad"
author: "Juan Gabriel Gomila & María Santos"
output: 
  ioslides_presentation:
    widescreen: true
    css: JB_style.css
    logo: Imgs/LogoCurso.png
    fig_height: 4
    fig_width: 10
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA)
```

# Conceptos básicos

## Probabilidad

Por ahora, nos basta la siguiente definición de probabilidad:

<l class = "definition">Probabilidad. </l>Medida de la certidumbre asociada a un suceso o evento que aún no ha sucedido y que se expresa como un número entre 0 y 1, ambos incluidos.

<div class = "example">
**Ejemplo**

- La probilidad de que salga cara cuando tiramos una moneda no trucada es $p = \frac{1}{2} = 0.5$
- La probilidad de que salga al tirar un dado no trucado nos salga 5 es $p = \frac{1}{6}$
</div>

Por lo general, si nos encontramos en un caso como los anteriores, la probabilidad la podemos calcular del siguiente modo:

$$p=\frac{\text{casos favorables}}{\text{casos posibles}}$$


## Variable aleatoria

<l class = "definition">[Variable aleatoria](https://es.wikipedia.org/wiki/Variable_aleatoria).</l> Una variable aleatoria es una función que asigna un valor, usualmente numérico, al resultado de un experimento aleatorio. Las hay de dos tipos: discretas y continuas.

- <l class = "definition">Variable aleatoria discreta.</l> Solamente puede tomar un número finito de valores.
- <l class = "definition">Variable aleatoria continua.</l> Puede tomar como valores un intervalo (finito o infinito) de números reales.

<div class = "example">
**Ejemplo**

La variable aleatoria $X$ que cuenta el número de caras que salen al tirar una moneda $n$ veces es una variable aleatoria discreta
</div>


## Funciones de probabilidad y densidad

- <l class = "definition">Función de probabilidad.</l> Asocia a cada punto del dominio de $X$ la probabilidad de que ésta lo asuma. Es útil cuando $X$ es v.a. discreta. De ser $X$ v.a. continua, la función de probabilidad es la función nula.

- <l class = "definition">Función de densidad.</l> Cuando $X$ es v.a. continua, la función de densidad describe la probabilidad relativa según la cual dicha variable aleatoria tomará determinado valor.


## Función de distribución

<l class = "definition">Función de distribución.</l> Describe la probabilidad de que $X$ tenga un valor menor o igual que $x$.

- Es continua por la derecha
- Es creciente
- Toma valores entre 0 y 1

## Esperanza de una variable aleatoria

<l class = "definition">Esperanza de una variable aleatoria discreta.</l> $E(X)= \sum_{i=1}^nx_i\cdot p\{X=x_i\}$. Es decir, es la suma del producto de todos los valores que puede tomar la variable aleatoria discreta por su probabilidad.

<l class = "definition">Esperanza de una variable aleatoria continua.</l> $E(X)= \int_{-\infty}^{\infty}x\cdot f(x)dx$. Es decir, es la integral de todos los valores que puede tomar la variable aleatoria continua por su función de densidad.

## Varianza de una variable aleatoria

<l class = "definition">Varianza.</l> $Var(X)=E((X-E(X))^2)$. Es decir, es una medida de dispersión definida como la esperanza del cuadrado de la desviación de dicha variable respecto a su media.

- De entre sus propiedades, una de las más interesantes es: $Var(X)=E(X^2)-(E(X))^2$

## Distribución de probabilidad

<l class = "definition">[Distribución de probabilidad](https://es.wikipedia.org/wiki/Distribución_de_probabilidad).</l> En teoría de la probabilidad y estadística, la distribución de probabilidad de una variable aleatoria es una función que asigna a cada suceso definido sobre la variable la probabilidad de que dicho suceso ocurra.

## Funciones de distribución en `R`

Dada cualquier variable aleatoria, $va$, `R` nos da cuatro funciones para poder trabajar con ellas:

* `dva(x,...)`: Función de densidad o de probabilidad $f(x)$ de la variable aleatoria para el valor  $x$ del dominio de definición.
* `pva(q,...)`: Función de distribución $F(x)$ de la variable aleatoria para el cuantil $q$.
* `qva(p,...)`: Cuantil $p$-ésimo de la variable aleatoria (el valor de $x$ más pequeño tal que $F(x)\geq p$).
* `rva(n,...)`: Generador de $n$ observaciones siguiendo la distribución de la variable aleatoria.


## Distribuciones discretas

<l class = "definition">Distribución discreta</l>

- [Bernoulli](https://es.wikipedia.org/wiki/Distribución_de_Bernoulli)
- [Binomial](https://es.wikipedia.org/wiki/Distribución_binomial)
- [Geométrica](https://es.wikipedia.org/wiki/Distribución_geométrica)
- [Hipergeométrica](https://es.wikipedia.org/wiki/Distribución_hipergeométrica)
- [Poisson](https://es.wikipedia.org/wiki/Distribución_de_Poisson)

## Distribución de Bernoulli

Si $X$ es variable aleatoria que mide el "número de éxitos" y se realiza un único experimento con dos posibles resultados (éxito, que toma valor 1, o fracaso, que toma valor 0), diremos que $X$ se distribuye como una Bernoulli con parámetro $p$

$$X\sim \text{Be}(p)$$

donde $p$ es la probabilidad de éxito y $q = 1-p$ es la probabilidad de fracaso.

- El **dominio** de $X$ será $X(\Omega) = \{0,1\}$
- La **función de probabilidad** vendrá dada por $$f(k) = p^k(1-p)^k =  \left\{
\begin{array}{rl}
     p & \text{si } k=0 
  \\ q & \text{si } k=1
  \\ 0 & \text{en cualquier otro caso}
\end{array}
\right.$$

## Distribución de Bernoulli

- La **función de distribución** vendrá dada por $$F(k) = \left\{
\begin{array}{rl}
     0 & \text{si } k<0 
  \\ q & \text{si } 0\le k<1
  \\ 1 & \text{si } k\ge 1
\end{array}
\right.$$
- **Esperanza** $E(X) = p$
- **Varianza** $Var(X) = pq$

## Distribución Binomial

Si $X$ es variable aleatoria que mide el "número de éxitos" y se realizan $n$ ensayos de Bernoulli independientes entre sí, diremos que $X$ se distribuye como una Binomial con parámetros $n$ y $p$

$$X\sim \text{B}(n,p)$$

donde $p$ es la probabilidad de éxito y $q = 1-p$ es la probabilidad de fracaso

- El **dominio** de $X$ será $X(\Omega) = \{0,1,2,\dots,n\}$
- La **función de probabilidad** vendrá dada por $$f(k) = {n\choose k}p^k(1-p)^{n-k} $$

## Distribución Binomial

- La **función de distribución** vendrá dada por $$F(k) = \left\{
\begin{array}{cl}
     0 & \text{si } k<0 
  \\ \sum_{i=0}^kf(k) & \text{si } 0\le k<n
  \\ 1 & \text{si } k\ge n
\end{array}
\right.$$
- **Esperanza** $E(X) = np$
- **Varianza** $Var(X) = npq$

## Distribución Binomial

```{r, echo = FALSE}
par(mfrow = c(1,2))
plot(dbinom(1:50,50,0.5),col = "purple", xlab = "", ylab = "", main = "Función de probabilidad de una B(50,0.5)")
plot(pbinom(1:50,50,0.5),col = "purple", xlab = "", ylab = "", main = "Función de distribución de una B(50,0.5)")
par(mfrow= c(1,1))

```

## Distribución Geométrica

Si $X$ es variable aleatoria que mide el "número de repeticiones independientes del experimento hasta haber conseguido éxito", diremos que $X$ se distribuye como una Geométrica con parámetro $p$

$$X\sim \text{Geom}(p)$$
donde $p$ es la probabilidad de éxito y $q = 1-p$ es la probabilidad de fracaso

- El **dominio** de $X$ será $X(\Omega) = \{0,1,2,\dots\}$ o bien $X(\Omega) = \{1,2,\dots\}$ en función de si empieza en 0 o en 1

- La **función de probabilidad** vendrá dada por $$f(k) = (1-p)^{k}p \qquad\text{ si empieza en 0}$$
$$f(k) = (1-p)^{k-1}p \qquad\text{ si empieza en 1}$$

## Distribución Geométrica
 
- **Esperanza** $E(X) = \frac{1-p}{p}$ si empieza en 0 y E$(X) = \frac{1}{p}$ si empieza en 1
- **Varianza** $Var(X) = \frac{1-p}{p^2}$
- No tiene memoria. Es decir, $p\{X>m+n:\ X>m\} = p\{X>n\}$

## Distribución Hipergeométrica

## Distribución de Poisson

Si $X$ es variable aleatoria que mide el "número de eventos en un cierto intervalo de tiempo", diremos que $X$ se distribuye como una Poisson con parámetro $\lambda$

$$X\sim \text{Po}(\lambda)$$
donde $\lambda$ representa el número de veces que se espera que ocurra el evento durante un intervalo dado

- El **dominio** de $X$ será $X(\Omega) = \{0,1,2,\dots\}$

- La **función de probabilidad** vendrá dada por $$f(k) = \frac{e^{-\lambda}\lambda^k}{k!}$$

## Distribución de Poisson
 
- **Esperanza** $E(X) = \lambda$
- **Varianza** $Var(X) = \lambda$


## Distribuciones discretas en R

R conoce las distribuciones de probabilidad más importantes.

Distribución |  Instrucción  |  Parámetros                                
--------------------|--------------------|--------------------
Binomial | `binom` | tamaño de la muestra $n$ y probabilidad de éxito $p$
Geométrica | `geom` | probabilidad de éxito $p$
Hipergeométrica | `hyper` | $N,M,n$
Poisson | `pois` | esperanza $\lambda$

## Distribuciones continuas

- Uniforme
- Exponencial
- Normal
- Khi cuadrado
- t de Student
- F de Fisher

## Distribución Uniforme

## Distribución Exponencial

## Distribución Normal

## Distribución Khi cuadrado

## Distribución t de Student

## Distribución F de Fisher

## Distribuciones continuas en R

Distribución |  Instrucción  |  Parámetros                                
--------------------|--------------------|--------------------
Uniforme | `unif` | mínimo y máximo
Exponencial | `exp` | $\lambda$
Normal | `norm` | media $\mu$, desviación típica $\sigma$
Khi cuadrado | `chisq` | grados de libertad
t de Student | `t` | grados de libertad
F de Fisher | `f` | los dos grados de libertad

## Distribuciones de probabilidad en R

Para cada una de las funciones anteriores, R sabe calcular cuatro funciones:

- Función densidad: añadiendo prefijo `d`
- Función de distribución de probabilidad: añadiendo prefijo `p`
- Cuantiles: añadiendo prefijo `q`
- Listas de números aleatorios generados con esta distribución: añadiendo prefijo `r`

## Distribución Normal en R

Si a la hora de llamar a alguna de las 4 funciones siguientes: `dnorm`, `pnorm`, `qnorm` o `rnorm` no especificásemos los parámetros de  la media ni la desviación típica, R entiende que se trata de la normal estándar: la $\mathcal{N}(0,1)$.

Es decir, R interpreta $\mu = 0$ y $\sigma = 1$

